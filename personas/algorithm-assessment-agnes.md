# Algorithm Assessment Agnes

<img alt="Headshot of Agnes" src="./images/image2.png" width="300">

- **Age**: 35

- **Education**
  - BA in Psychology
    - took some math-heavy behavioral economics and research courses, 
      intro CS
  - Subsequently earned an MS Data Science.

- **Professional Experience**
  - After getting her masters degree at 26, she spent three years 
    working as a data scientist at a financial institution.
    She found that her work was often ignored by bank management.

  - Moved to a startup coercing data 
    into looking sort of like a hockey stick.
    She left after just a year.

- **Organizational Home** & **Foundational experience in practice**

  For the past 6 years, Agnes has been Working at SaiFTY, 
  a [B Corp](https://en.wikipedia.org/wiki/Benefit_corporation)
  with the mission of reducing AI harm
  by working with system developers 
  to identify and mitigate risks.

- **Engineering Capacities**:
  Knows Python, dabbled in PyTorch, some visualization libraries,
  and data engineering frameworks like Spark.
  Uses Jupyter Notebooks with Pandas in her day to day.

- **Attentiveness to task**
  - If she chose to use the tool,
    then she's going to be highly attentive
    and play around with the parameters.

  - If she's pressured to use the tool by someone else,
    then she is moderately inattentive,
    only going down the most obvious path of actions.

- **Customers**
  - Companies affected by legislation 
    requiring second-party audits of AI systems.

  - Companies that, for PR purposes, want to be able 
    to show that they're following responsible AI best practices
    in having an audit conducted
    and producing results.

  - Companies doing projects for which AI failures
    would expose them to significant legal liability
    and need assurance that their systems work.

- **Stakeholders**
  - The organization Agnes works for
  - The organization that they're auditing
    - The engineers of the system under audit
    - The manager in charge of the project
  - The users of the system under audit
  - Non-users on whom the system acts
    - For instance, in an automated system for hiring,
      candidates are not users,
      but they are among the main parties
      affected by the system.

- **Relationship with risks that are surfaced -- 
  what does she do with them now, what would she ideally do?**

  She writes a report detailing the problems,
  and their potential mitigation paths.
  What the company does with this depends
  on their motivations:

  - If they're in this to comply with regulations,
    they'll do the minimum required by the legislation.

  - If they're in it for PR reasons,
    they probably make surface-level changes
    so they can claim to have addressed the problems,
    regardless of whether they have actually done so.

  - If they're worried about legal liability,
    they'll make changes up to the point
    where the cost of the changes is greater
    than the expected loss from being sued.

  Ideally, she would be able to ensure
  that the problems were actually mitigated.
  This is a limitation of second-party audits

  - Unlike a first-party auditor,
    she doesn't have authority within the organization,

  - Unlike a third-party auditor,
    she can't get the media to run stories on the company
    if they don't respond to the problem appropriately
    – otherwise she'd have no more business.


## References

- [Building and Auditing Fair Algorithms: 
   A Case Study in Candidate Screening](
    https://evijit.github.io/docs/pymetrics_audit_FAccT.pdf
  )
  - Author [Christo Wilson](https://cbw.sh/)

- [Outsider Oversight:
  Designing a Third Party Audit Ecosystem for AI Governance](
    https://arxiv.org/pdf/2206.04737.pdf
  )

  > "**even well-executed algorithmic audit results may get co-opted by 
  >  audit targets and used to disguise deeper failures**. The 
  >  controversial facial recognition company Clearview AI, for 
  >  example, claimed to be "100% accurate across all demographic 
  >  groups according to the ACLU’s facial recognition accuracy 
  >  methodology" but failed to address the ethical and legal 
  >  challenges that accompany its sourcing of face data, which has 
  >  been subject to numerous legal actions (e.g., in California, 
  >  Illinois, the European Union)"

  > By convention, audits are classified into three types [29]. 
  > "First party" audits are conducted by a company of its own 
  > products. Many AI ethics teams can be conceived of as fulfilling 
  > a first-party audit role. "Second party" audits are performed by 
  > a contractual counterparty or an entity hired by that contractual 
  > counterparty. Second party audits typically ensure compliance 
  > with contract terms. As applied to AI, public sector procurement 
  > of AI products may require a second party audit to assess bias, 
  > as has been the case for legislative proposals to regulate facial 
  > recognition technology. "Third party" audits are conducted by 
  > ostensibly independent parties engaged specifically to conduct 
  > the audit, typically subject to pre-determined auditing standards.

- [Algorithmic Accountability Act of 2022](
    https://www.congress.gov/bill/117th-congress/house-bill/6580/text
  )

- [Audit & Assurance Senior, AI/Algorithm – Deloitte](
    https://web.archive.org/web/20220819175429/https://apply.deloitte.com/careers/JobDetail/Audit-Assurance-Senior-AI-Algorithm/99280
  )
  
  > "Familiarity with AI and analytical 
  > software packages/tools/programming languages 
  > (e.g., SAS, R, Python, Spark, Hadoop Big Data, etc.)"
